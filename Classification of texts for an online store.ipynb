{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWwRj9mb61t0"
      },
      "source": [
        "# Classification of texts for an online store\n",
        "\n",
        "**Problem situation:** Wikishop is launching a new service. Now users can edit and supplement product descriptions, just like in wiki communities. I.e. clients propose their edits and comment on the changes of others.\n",
        "\n",
        "**Goal:** creating a tool that will look for toxic comments and submit them for moderation.\n",
        "\n",
        "**Task:** building a model for classifying comments into positive and negative.\n",
        "\n",
        "**Data:** Tweets with edit toxicity markup. ```Tag:``` comment text. ```Target trait:``` binary toxicity classification.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "* The F1 metric must be at least 0.75.\n",
        "\n",
        "In this work, we will pay a lot of attention to high-quality data preprocessing: their cleaning from extra characters and auxiliary words, lemmatization taking into account parts of speech, and vectorization through TF-IDF counting.\n",
        "\n",
        "Then, using cross-validation and randomized hyperparameter enumeration, we will test 3 models:\n",
        "\n",
        "* Logistic regression;\n",
        "* Light GBM;\n",
        "* Catboost.\n",
        "\n",
        "Let's start by importing the libraries:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZfDWB-D63Kt",
        "outputId": "21824597-b877-4553-c9b2-2335192e723b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, wordnet as wn\n",
        "from tqdm import notebook\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     cross_val_score,\n",
        "                                     RandomizedSearchCV)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yX4u-ES62Os"
      },
      "source": [
        "## 1. Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFnaA56sh4uJ"
      },
      "source": [
        "В этом разделе мы загрузим, изучим и преобработаем наши данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9DYQEEBH9YP"
      },
      "source": [
        "### 1.1. Primary analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owx_KECtIEAV"
      },
      "source": [
        "Let's write a function to quickly get information about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85WxUHjz70We"
      },
      "outputs": [],
      "source": [
        "def df_read(file_path):\n",
        "    df = pd.read_csv(file_path, index_col=[0])\n",
        "    print(df.info(), '\\n')\n",
        "    print('Количество дубликатов:', '\\n', sum(df.duplicated()), '\\n')\n",
        "    print('Количество пропусков:', '\\n', df.isna().sum(), '\\n')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVQvSi328oWF",
        "outputId": "805b72d4-3c9d-4805-aa59-1e997fb6fb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 159292 entries, 0 to 159450\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159292 non-null  object\n",
            " 1   toxic   159292 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.6+ MB\n",
            "None \n",
            "\n",
            "Количество дубликатов: \n",
            " 0 \n",
            "\n",
            "Количество пропусков: \n",
            " text     0\n",
            "toxic    0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df_read('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxVEPA9LiGDE"
      },
      "source": [
        "We see that there are no omissions and duplicates. Let's see what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MD8c0uEZ_KV_",
        "outputId": "83b09d48-e256-4001-fb3d-aaa1a49ea1e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fe967f87-4c24-4877-8cec-9b4d42d6aa3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe967f87-4c24-4877-8cec-9b4d42d6aa3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe967f87-4c24-4877-8cec-9b4d42d6aa3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe967f87-4c24-4877-8cec-9b4d42d6aa3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1pgnY7_iOsG"
      },
      "source": [
        "The very first 5 lines demonstrate there's quite a lot of garbage in the text. But there is another possible problem - an imbalance of classes in the target trait. Let's look at the quantity of values in the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MtehkJ3Em6q",
        "outputId": "209ec8ac-612c-4fbd-cf0c-3267fa646256"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    143106\n",
              "1     16186\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['toxic'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inz4zvRIicSr"
      },
      "source": [
        "Indeed, there is a big imbalance. Let's eliminate it at the model training stage by setting the `class_weight` attribute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MnFxrOZIF_x"
      },
      "source": [
        "### 1.2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNmqlG1Sjmxe"
      },
      "source": [
        "Let's extract the target feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyVijtVXIcqa"
      },
      "outputs": [],
      "source": [
        "target = df['toxic']\n",
        "features = df['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2rmPuJejtxh"
      },
      "source": [
        "Now let's start cleaning learning features from stop words and extra characters, as well as lemmatization, considering differents parts of speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abZMogvxvT43"
      },
      "outputs": [],
      "source": [
        "stoplist = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXhq9DxlvVAm"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HyYURHuuJpQ"
      },
      "outputs": [],
      "source": [
        "def text_preprocess(row):\n",
        "  row = row.lower()\n",
        "  row = re.sub('[^a-zA-Z0-9]', ' ', row)\n",
        "  row = re.sub('[\\s+]', ' ', row)\n",
        "  row = ' '.join([i for i in row.split() if i not in stoplist])\n",
        "\n",
        "  wn_map = {'N' : wn.NOUN, 'V' : wn.VERB, 'J' : wn.ADJ, 'R' : wn.ADV}\n",
        "  tagged = pos_tag(row.split())\n",
        "  lemmatized = ' '.join([lemmatizer.lemmatize(word, pos=wn_map.get(pos[0], wn.NOUN)) for word, pos in tagged])\n",
        "  return lemmatized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__R1uyFHj71q"
      },
      "source": [
        "We've written the function, now we shall apply and check it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_aHmevBKxhY"
      },
      "outputs": [],
      "source": [
        "features = features.str.lower()\n",
        "features = features.apply(lambda x: text_preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRaCuO22ALx7",
        "outputId": "46f2af49-2c08-42fa-96e2-176ac1f9cd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(159292,) \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0    explanation edits make username hardcore metal...\n",
              "1    aww match background colour seemingly stuck th...\n",
              "2    hey man really try edit war guy constantly rem...\n",
              "3    make real suggestion improvement wonder sectio...\n",
              "4                        sir hero chance remember page\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(features.shape, '\\n')\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umirpdyvkAII"
      },
      "source": [
        "Great, it worked! Now I don’t have to pronounce words with the ```73913``` index!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBMMdiMqkZUK"
      },
      "source": [
        "Now let's divide the features into training and test samples in the proportion of 50/50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwEVMvEONPdq"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 11235\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features,\n",
        "                                                                            target,\n",
        "                                                                            test_size=0.5,\n",
        "                                                                            random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNp5fTRIOFLA",
        "outputId": "59659859-7123-4e27-ff57-155ac51f8495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(79646,)\n",
            "(79646,)\n",
            "(79646,)\n",
            "(79646,)\n"
          ]
        }
      ],
      "source": [
        "print(features_train.shape)\n",
        "print(features_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxz5fc_W1YjR"
      },
      "source": [
        "Let's look at the ratio of classes after dividing into samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibBEF-Hh1lPy",
        "outputId": "c96b4e95-299f-4a84-c439-ce1ae210aa9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    71545\n",
              "1     8101\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLOBnEfR5_tw"
      },
      "source": [
        "We will try to eliminate this imbalance during the training using class weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul0XCs1aLlcK"
      },
      "source": [
        "We'll vectorize the text using TF-IDF in a following manner: at the cross-validation stage, we will use the vectorizer as part of the pipeline (which will include features without vectorization) so that there is no data leakage between the training and validation samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8yvqklSErzX"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeG5hW6PPZRZ"
      },
      "source": [
        "Let's go in order: logistic regression, Light GBM and CatBoost. So let's start with..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWqexjf6PJC0"
      },
      "source": [
        "### 2.1. Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7Kn_K9yPbhw"
      },
      "source": [
        "Yep. We will get the F1 metric during cross-validation on 5 blocks. First, let's create a Pipeline and get the baseline results for the model without class weighting. We'll also try to set the value of the strength of the regularization with enumeration, and at the same time set the number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a-NHak6-mQo"
      },
      "outputs": [],
      "source": [
        "pipeline_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                            ('lr', LogisticRegression())])\n",
        "\n",
        "param_grid = { 'lr__C' : np.arange(2, 20, 2),\n",
        "              'lr__max_iter' : np.arange(100, 500, 100)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMXU_gFPHn4Y"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "lr_random = RandomizedSearchCV(pipeline_lr,\n",
        "param_distributions=param_grid,\n",
        "cv=5,\n",
        "scoring='f1',\n",
        "verbose=100,\n",
        "random_state=RANDOM_STATE)\n",
        "\n",
        "lr_random.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj_Vcw2ZP4Uk",
        "outputId": "64dd308c-97ad-41e3-87a5-8f893cd26236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая логистическая регрессия получается при следующих гиперпараметрах: \n",
            " {'lr__max_iter': 100, 'lr__C': 16}, её показатель F1: 0.771\n"
          ]
        }
      ],
      "source": [
        "print(f'Лучшая логистическая регрессия получается при следующих гиперпараметрах: \\n \\\n",
        "{lr_random.best_params_}, \\\n",
        "её показатель F1: {lr_random.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJYQrSjv6Y_-"
      },
      "source": [
        "Without class balancing, the best measure F1 of the logistic regression was 0.771. Now let's try to balance the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHiXRkd47AGK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "pipeline_lr_b = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                            ('lr', LogisticRegression(class_weight='balanced'))])\n",
        "\n",
        "lr_random_b = RandomizedSearchCV(pipeline_lr_b,\n",
        "param_distributions=param_grid,\n",
        "cv=5,\n",
        "scoring='f1',\n",
        "verbose=100,\n",
        "random_state=RANDOM_STATE)\n",
        "\n",
        "lr_random_b.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhEQCXevZ2RM",
        "outputId": "1009cc97-ca87-497b-c7c5-8ad2f21e9479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая логистическая регрессия со сбалансированными классами \n",
            "получается при следующих гиперпараметрах: {'lr__max_iter': 300, 'lr__C': 18}, её показатель F1: 0.765\n"
          ]
        }
      ],
      "source": [
        "print(f'Лучшая логистическая регрессия со сбалансированными классами \\n\\\n",
        "получается при следующих гиперпараметрах: {lr_random_b.best_params_}, её показатель F1: \\\n",
        "{lr_random_b.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGsI-RhCPTuq"
      },
      "source": [
        "The logistic regression with balanced classes has an F1 score of 0.765, i.e. even worse than without balancing. Let's try to compare models with gradient boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_UitKGhPeK6"
      },
      "source": [
        "### 2.2. LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE3UWMN1Pfez"
      },
      "source": [
        "Let's create a new pipeline, and at the same time a dictionary for iterating over hyperparameters. Since training a model with gradient boosting takes a lot of time, we set 5 iterations to enumerate the hyperparameters.\n",
        "\n",
        "First, let's test the model without eliminating class imbalances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s9AQsxnBHnl"
      },
      "outputs": [],
      "source": [
        "pipeline_lgb = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
        "                            ('clf', LGBMClassifier(random_state=RANDOM_STATE))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1Y62EiXHowQ",
        "outputId": "dd0587ee-e1d5-4f18-d7e1-281480fd71fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'clf__num_leaves': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
              "        36, 38, 40, 42, 44, 46, 48]),\n",
              " 'clf__reg_lambda': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
              " 'clf__max_depth': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
              "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68,\n",
              "        70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]),\n",
              " 'clf__learning_rate': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
              "        0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {'num_leaves': np.arange(2, 50, 2),\n",
        "              'reg_lambda' : np.arange(1, 20, 2),\n",
        "              'max_depth' : np.arange(2, 100, 2),\n",
        "              'learning_rate' : np.arange(0.1, 1, 0.05)}\n",
        "\n",
        "param_grid = {'clf__' + key: param_grid[key] for key in param_grid}\n",
        "\n",
        "param_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmpBlom5Q-OD"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "lgb_random = RandomizedSearchCV(pipeline_lgb,\n",
        "                                param_distributions=param_grid,\n",
        "                                cv=5,\n",
        "                                scoring='f1',\n",
        "                                verbose=10,\n",
        "                                n_iter=5,\n",
        "                                random_state=RANDOM_STATE\n",
        "                                )\n",
        "\n",
        "lgb_random.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa8Fo3VMStyj",
        "outputId": "04230a67-aafc-4b06-e132-999374c63f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая модель LightGBM получается при следующих гиперпараметрах: \n",
            " {'clf__reg_lambda': 19, 'clf__num_leaves': 38, 'clf__max_depth': 96, 'clf__learning_rate': 0.7000000000000002}. \n",
            " Её метрика F1 составляет 0.762\n"
          ]
        }
      ],
      "source": [
        "print(f'Лучшая модель LightGBM получается при следующих гиперпараметрах: \\n \\\n",
        "{lgb_random.best_params_}. \\n \\\n",
        "Её метрика F1 составляет {lgb_random.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCGuatvUTdJi"
      },
      "source": [
        "Now let's evaluate the model with balanced classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fo0EeljiOyD"
      },
      "outputs": [],
      "source": [
        "pipeline_lgb_b = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
        "                            ('clf', LGBMClassifier(random_state=RANDOM_STATE, class_weight='balanced'))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rECB1ybUic4p"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "lgb_random_b = RandomizedSearchCV(pipeline_lgb_b,\n",
        "                                param_distributions=param_grid,\n",
        "                                cv=5,\n",
        "                                scoring='f1',\n",
        "                                verbose=10,\n",
        "                                n_iter=5,\n",
        "                                random_state=RANDOM_STATE\n",
        "                                )\n",
        "\n",
        "lgb_random_b.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrhACCi0n2e7",
        "outputId": "32276ce1-e5d1-482a-9f6c-04cb99da6171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая модель LightGBM со сбалансированными классами получается при следующих гиперпараметрах: \n",
            " {'clf__reg_lambda': 17, 'clf__num_leaves': 44, 'clf__max_depth': 70, 'clf__learning_rate': 0.7000000000000002}. \n",
            " Её метрика F1 составляет 0.742\n"
          ]
        }
      ],
      "source": [
        "print(f'Лучшая модель LightGBM со сбалансированными классами получается при следующих гиперпараметрах: \\n \\\n",
        "{lgb_random_b.best_params_}. \\n \\\n",
        "Её метрика F1 составляет {lgb_random_b.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7goymF6XPpgw"
      },
      "source": [
        "### 2.3. CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6q31gnKn-Y2"
      },
      "source": [
        "So far we've seen that the elimination of class imbalance only worsens the quality of the models. Since CatBoost oftentimes is trained longer than LightGBM, we'll try not to set its ```auto_class_weights``` parameter immediately during training. We will also limit the number of iterations to 5 and the number of blocks for cross-validation to 3.\n",
        "\n",
        "We also pre-set the growth strategy \"Lossguide\", which allows you to build trees sequentially, \"petal by petal\", separating only the petals with the minimum values of the error function.\n",
        "\n",
        "Other hyperparameters, such as the number of leaves, the depth of the tree, and the learning rate, will be iterated over in a random order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwK5xHm5T_kp"
      },
      "outputs": [],
      "source": [
        "pipeline_cb = Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
        "                            ('clf', CatBoostClassifier(iterations=30,\n",
        "                                                       random_state=RANDOM_STATE,\n",
        "                                                       grow_policy='Lossguide'))])\n",
        "\n",
        "param_grid = {'num_leaves': np.arange(2, 50, 2),\n",
        "              'max_depth' : np.arange(2, 16, 2),\n",
        "              'learning_rate' : np.arange(0.1, 1, 0.05)}\n",
        "\n",
        "param_grid = {'clf__' + key: param_grid[key] for key in param_grid}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti08yS-VTeS9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "cb_random = RandomizedSearchCV(pipeline_cb,\n",
        "                                param_distributions=param_grid,\n",
        "                                cv=3,\n",
        "                                scoring='f1',\n",
        "                                verbose=10,\n",
        "                                random_state=RANDOM_STATE,\n",
        "                               n_iter=5,\n",
        "                               error_score='raise'\n",
        "                                )\n",
        "\n",
        "cb_random.fit(features_train, target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y71y5EJeTbBN",
        "outputId": "aa4bd58e-1917-41db-e458-63cb79e46747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Лучшая модель CatBoost получается при следующих гиперпараметрах: \n",
            " {'clf__num_leaves': 6, 'clf__max_depth': 4, 'clf__learning_rate': 0.7000000000000002}. \n",
            " Её метрика F1 составляет 0.703\n"
          ]
        }
      ],
      "source": [
        "print(f'Лучшая модель CatBoost получается при следующих гиперпараметрах: \\n \\\n",
        "{cb_random.best_params_}. \\n \\\n",
        "Её метрика F1 составляет {cb_random.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92YIb3jTnllj"
      },
      "source": [
        "The F1 metric turned out to be lower than that of all other models. Welp.\n",
        "\n",
        "But before culling the model, let's try one thing: you can set text features in CatBoost, and then we won't even need to use TFIDF.\n",
        "\n",
        "Let's set the best hyperparameters that we got as a result of the selection, along with a set of texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kAshMity3Ui"
      },
      "outputs": [],
      "source": [
        "features_catboost = pd.DataFrame(features_train, columns=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWdLwAZMJLQT"
      },
      "outputs": [],
      "source": [
        "cb_model = CatBoostClassifier(grow_policy='Lossguide',\n",
        "                              random_state=RANDOM_STATE,\n",
        "                              learning_rate=0.7,\n",
        "                              num_leaves=6,\n",
        "                              max_depth=4,\n",
        "                              text_features=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3SAWDmbLIcz"
      },
      "outputs": [],
      "source": [
        "cb_f1 = cross_val_score(cb_model, features_catboost, target_train, cv=5, scoring='f1')\n",
        "print(f'Значение метрики F1 для CatBoost, обученной на текстовых признаках, составляет {cb_f1.mean():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj-bGdp85aCt"
      },
      "source": [
        "The value of the F1 metric for CatBoost has become significantly better - 0.758. Just for an experiment let's try to balance the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-colCIRp5rst"
      },
      "outputs": [],
      "source": [
        "cb_model_b = CatBoostClassifier(grow_policy='Lossguide',\n",
        "                              auto_class_weights='Balanced',\n",
        "                              random_state=RANDOM_STATE,\n",
        "                              learning_rate=0.7,\n",
        "                              num_leaves=6,\n",
        "                              max_depth=4,\n",
        "                              text_features=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEhnseVT5xhp"
      },
      "outputs": [],
      "source": [
        "cb_f1_b = cross_val_score(cb_model_b, features_catboost, target_train, cv=5, scoring='f1')\n",
        "print(f'Значение метрики F1 для CatBoost со сбалансированными классами, \\n \\\n",
        "обученной на текстовых признаках, составляет {cb_f1_b.mean():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USCnRKqW_8dU"
      },
      "source": [
        "And again, balancing the classes of the target feature worsened the F1-measure of the model (0.739). But on the other hand, we've found out that it might be better to leave texts unvectorized using Catboost, since text features can be specified in the hyperparameters of the model and that can result in higher metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMa2ADjQTb7y"
      },
      "source": [
        "### 2.4. Comparing the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPaIPYz-ATFN"
      },
      "source": [
        "Since models without class balancing performed better during each test, we will compare\n",
        " their best metrics in the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y27ESwebn6mN"
      },
      "source": [
        "\n",
        "\n",
        " Model | F1-score  | Duration of training, tuning and cross-validation\n",
        "-----| -------|----------\n",
        "Logistic regression| 0.771 | 10 min 32 sec\n",
        "Light GBM | 0.762 | 15 min 55 sec\n",
        "CatBoost | 0.758 | 25 min 32 sec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M-gN79gpIiu"
      },
      "source": [
        "Our clear winner is logistic regression trained on 100 iterations with a regularization strength of 16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ep3S4a1HpBv"
      },
      "source": [
        "## 3. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3wyQIO7eaUK"
      },
      "source": [
        "The moment of truth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wnwJ2k4G6s5"
      },
      "source": [
        "### 3.1. Metrics on the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Ep1d-hHr8K",
        "outputId": "83f6a0b8-7b9e-43e6-b6d2-4e6b4645dd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Метрика F1 логистической регрессии на тестовой выборке составляет: 0.775\n"
          ]
        }
      ],
      "source": [
        "predictions = lr_random.predict(features_test)\n",
        "print(f'Метрика F1 логистической регрессии на тестовой выборке \\\n",
        "составляет: {f1_score(target_test, predictions):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfuyyrBWHYM9"
      },
      "source": [
        "Our logistic regression has a final F1 score of 0.775, it has successfully passed the critical barrier of 0.75!\n",
        "\n",
        "But for reliability, we check the model for its sanity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8F-ssAHiQx"
      },
      "source": [
        "### 3.2. Sanity check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH08yE9YFiw_"
      },
      "source": [
        "For the sanity check we are to evaluate the quality of predictions of the constant model, which will consider all comments to be negative by default (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCL8izCVFtUs",
        "outputId": "1872dc45-b07d-4baa-f112-91804d1949d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Метрика F1 константной модели: 0.184\n"
          ]
        }
      ],
      "source": [
        "dummy_predictions = pd.Series(1, index=features_test.index)\n",
        "\n",
        "print(f'Метрика F1 константной модели: {f1_score(target_test, dummy_predictions):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AjihhNVpqf4"
      },
      "source": [
        "The F1 of the constant model is only 0.184! Thus, our logistic regression has successfully passed through the sanity check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXcaXRQ2Hu_u"
      },
      "source": [
        "## 4. Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp1jBP8vHxyc"
      },
      "source": [
        "## Results\n",
        "\n",
        "So that's what we've done:\n",
        "\n",
        "**1. Preprocessing.**\n",
        "\n",
        "* Downloaded and studied the data, revealed an imbalance in the classes of the target trait;\n",
        "* Prepared data for training: cleaned, lemmatized and divided into samples;\n",
        "* Created a pipeline for data vectorization during model cross-validation in order to prevent data leakage.\n",
        "\n",
        "**2. Training.**\n",
        "\n",
        "* With the help of randomized selection, we selected the best hyperparameters for models without gradient boosting and with it: logistic regression, Light GBM and CatBoost;\n",
        "* Discovered that **F1-measure of models is higher if the imbalance of classes is not eliminated**;\n",
        "* Compared model metrics (training time and F1 value) taking into account training time, hyperparameter fitting and cross-validation. Based on the results of the comparison, we chose simple **logistic regression** with the highest F1(**0.771**);\n",
        "* Hyperparameters of the selected model: {'max_iter': 100, 'C': 16}.\n",
        "\n",
        "**3. Testing.**\n",
        "\n",
        "* We evaluated the quality of predictions of the selected model on the test sample.\n",
        "* Calculated a final F1 score of **0.775**, which is higher than the given threshold of 0.75.\n",
        "* Checked the model for adequacy using a constant model whose F1 score was 0.184.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAI9yovic2kL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}